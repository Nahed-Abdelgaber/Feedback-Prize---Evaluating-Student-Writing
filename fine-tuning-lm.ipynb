{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --quiet datasets transformers[sentencepiece]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-31T05:48:11.734580Z","iopub.execute_input":"2021-12-31T05:48:11.734958Z","iopub.status.idle":"2021-12-31T05:48:23.419571Z","shell.execute_reply.started":"2021-12-31T05:48:11.734863Z","shell.execute_reply":"2021-12-31T05:48:23.418476Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!apt install --quiet git-lfs","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:48:24.609386Z","iopub.execute_input":"2021-12-31T05:48:24.609723Z","iopub.status.idle":"2021-12-31T05:48:30.000789Z","shell.execute_reply.started":"2021-12-31T05:48:24.609691Z","shell.execute_reply":"2021-12-31T05:48:29.999786Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:48:30.004025Z","iopub.execute_input":"2021-12-31T05:48:30.004647Z","iopub.status.idle":"2021-12-31T05:48:32.256339Z","shell.execute_reply.started":"2021-12-31T05:48:30.004599Z","shell.execute_reply":"2021-12-31T05:48:32.255431Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"remote_dataset = load_dataset(\"NahedAbdelgaber/evaluating-student-writing\", split=\"train\")\nremote_dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:48:32.258163Z","iopub.execute_input":"2021-12-31T05:48:32.258467Z","iopub.status.idle":"2021-12-31T05:48:37.140002Z","shell.execute_reply.started":"2021-12-31T05:48:32.258423Z","shell.execute_reply":"2021-12-31T05:48:37.138706Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:48:37.142069Z","iopub.execute_input":"2021-12-31T05:48:37.142947Z","iopub.status.idle":"2021-12-31T05:48:37.209724Z","shell.execute_reply.started":"2021-12-31T05:48:37.142903Z","shell.execute_reply":"2021-12-31T05:48:37.208670Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM\n\nmodel_checkpoint = \"distilbert-base-uncased\"\nmodel = AutoModelForMaskedLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:48:58.350524Z","iopub.execute_input":"2021-12-31T05:48:58.350955Z","iopub.status.idle":"2021-12-31T05:49:15.484898Z","shell.execute_reply.started":"2021-12-31T05:48:58.350913Z","shell.execute_reply":"2021-12-31T05:49:15.483899Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:15.486917Z","iopub.execute_input":"2021-12-31T05:49:15.487207Z","iopub.status.idle":"2021-12-31T05:49:15.495168Z","shell.execute_reply.started":"2021-12-31T05:49:15.487164Z","shell.execute_reply":"2021-12-31T05:49:15.494262Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"text = \"This is a great [MASK].\"","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:15.497281Z","iopub.execute_input":"2021-12-31T05:49:15.498081Z","iopub.status.idle":"2021-12-31T05:49:15.506590Z","shell.execute_reply.started":"2021-12-31T05:49:15.498036Z","shell.execute_reply":"2021-12-31T05:49:15.505471Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:15.509748Z","iopub.execute_input":"2021-12-31T05:49:15.510497Z","iopub.status.idle":"2021-12-31T05:49:21.684218Z","shell.execute_reply.started":"2021-12-31T05:49:15.510450Z","shell.execute_reply":"2021-12-31T05:49:21.683118Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch\n\ninputs = tokenizer(text, return_tensors=\"pt\")\ntoken_logits = model(**inputs).logits\n# Find the location of [MASK] and extract its logits\nmask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\nmask_token_logits = token_logits[0, mask_token_index, :]\n# Pick the [MASK] candidates with the highest logits\ntop_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n\nfor token in top_5_tokens:\n    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:21.685862Z","iopub.execute_input":"2021-12-31T05:49:21.686244Z","iopub.status.idle":"2021-12-31T05:49:23.675830Z","shell.execute_reply.started":"2021-12-31T05:49:21.686199Z","shell.execute_reply":"2021-12-31T05:49:23.674822Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples):\n    result = tokenizer(examples[\"text\"])\n    if tokenizer.is_fast:\n        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n    return result\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:23.677550Z","iopub.execute_input":"2021-12-31T05:49:23.678922Z","iopub.status.idle":"2021-12-31T05:49:23.685637Z","shell.execute_reply.started":"2021-12-31T05:49:23.678873Z","shell.execute_reply":"2021-12-31T05:49:23.684575Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Use batched=True to activate fast multithreading!\ntokenized_datasets = remote_dataset.map(\n    tokenize_function, batched=True, remove_columns=[\"text\"]\n)\ntokenized_datasets","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:23.689132Z","iopub.execute_input":"2021-12-31T05:49:23.689570Z","iopub.status.idle":"2021-12-31T05:49:56.044046Z","shell.execute_reply.started":"2021-12-31T05:49:23.689525Z","shell.execute_reply":"2021-12-31T05:49:56.042954Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenizer.model_max_length","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:56.046067Z","iopub.execute_input":"2021-12-31T05:49:56.046427Z","iopub.status.idle":"2021-12-31T05:49:56.055990Z","shell.execute_reply.started":"2021-12-31T05:49:56.046381Z","shell.execute_reply":"2021-12-31T05:49:56.054914Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Slicing produces a list of lists for each feature\ntokenized_samples = tokenized_datasets[:10]\n\nfor idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n    print(f\"'>>> essay {idx} length: {len(sample)}'\")","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:56.057995Z","iopub.execute_input":"2021-12-31T05:49:56.058318Z","iopub.status.idle":"2021-12-31T05:49:56.408683Z","shell.execute_reply.started":"2021-12-31T05:49:56.058273Z","shell.execute_reply":"2021-12-31T05:49:56.407467Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"remote_dataset['text'][:5]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T06:48:46.956747Z","iopub.execute_input":"2021-12-30T06:48:46.957236Z","iopub.status.idle":"2021-12-30T06:48:47.154534Z","shell.execute_reply.started":"2021-12-30T06:48:46.957185Z","shell.execute_reply":"2021-12-30T06:48:47.153749Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"chunk_size = 128","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:56.412249Z","iopub.execute_input":"2021-12-31T05:49:56.412893Z","iopub.status.idle":"2021-12-31T05:49:56.417848Z","shell.execute_reply.started":"2021-12-31T05:49:56.412844Z","shell.execute_reply":"2021-12-31T05:49:56.416823Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"concatenated_examples = {\n    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n}\ntotal_length = len(concatenated_examples[\"input_ids\"])\nprint(f\"'>>> Concatenated reviews length: {total_length}'\")","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:56.421067Z","iopub.execute_input":"2021-12-31T05:49:56.421677Z","iopub.status.idle":"2021-12-31T05:49:56.430600Z","shell.execute_reply.started":"2021-12-31T05:49:56.421634Z","shell.execute_reply":"2021-12-31T05:49:56.429485Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"chunks = {\n    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n    for k, t in concatenated_examples.items()\n}\n\nfor chunk in chunks[\"input_ids\"]:\n    print(f\"'>>> Chunk length: {len(chunk)}'\")","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:56.431952Z","iopub.execute_input":"2021-12-31T05:49:56.432933Z","iopub.status.idle":"2021-12-31T05:49:56.445308Z","shell.execute_reply.started":"2021-12-31T05:49:56.432838Z","shell.execute_reply":"2021-12-31T05:49:56.443796Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    # Compute length of concatenated texts\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the last chunk if it's smaller than chunk_size\n    total_length = (total_length // chunk_size) * chunk_size\n    # Split by chunks of max_len\n    result = {\n        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n        for k, t in concatenated_examples.items()\n    }\n    # Create a new labels column\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:56.446748Z","iopub.execute_input":"2021-12-31T05:49:56.447640Z","iopub.status.idle":"2021-12-31T05:49:56.456358Z","shell.execute_reply.started":"2021-12-31T05:49:56.447596Z","shell.execute_reply":"2021-12-31T05:49:56.455253Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"lm_datasets = tokenized_datasets.map(group_texts, batched=True)\nlm_datasets","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:49:56.458324Z","iopub.execute_input":"2021-12-31T05:49:56.459102Z","iopub.status.idle":"2021-12-31T05:51:07.314258Z","shell.execute_reply.started":"2021-12-31T05:49:56.459054Z","shell.execute_reply":"2021-12-31T05:51:07.313296Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(lm_datasets[1][\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:51:07.316360Z","iopub.execute_input":"2021-12-31T05:51:07.316755Z","iopub.status.idle":"2021-12-31T05:51:07.327063Z","shell.execute_reply.started":"2021-12-31T05:51:07.316693Z","shell.execute_reply":"2021-12-31T05:51:07.325838Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:51:07.329858Z","iopub.execute_input":"2021-12-31T05:51:07.330548Z","iopub.status.idle":"2021-12-31T05:51:07.523474Z","shell.execute_reply.started":"2021-12-31T05:51:07.330490Z","shell.execute_reply":"2021-12-31T05:51:07.522521Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"samples = [lm_datasets[i] for i in range(2)]\nfor sample in samples:\n    _ = sample.pop(\"word_ids\")\n\nfor chunk in data_collator(samples)[\"input_ids\"]:\n    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:51:07.525235Z","iopub.execute_input":"2021-12-31T05:51:07.525563Z","iopub.status.idle":"2021-12-31T05:51:07.547179Z","shell.execute_reply.started":"2021-12-31T05:51:07.525506Z","shell.execute_reply":"2021-12-31T05:51:07.546163Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import collections\nimport numpy as np\n\nfrom transformers import default_data_collator\n\nwwm_probability = 0.2\n\n\ndef whole_word_masking_data_collator(features):\n    for feature in features:\n        word_ids = feature.pop(\"word_ids\")\n\n        # Create a map between words and corresponding token indices\n        mapping = collections.defaultdict(list)\n        current_word_index = -1\n        current_word = None\n        for idx, word_id in enumerate(word_ids):\n            if word_id is not None:\n                if word_id != current_word:\n                    current_word = word_id\n                    current_word_index += 1\n                mapping[current_word_index].append(idx)\n\n        # Randomly mask words\n        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n        input_ids = feature[\"input_ids\"]\n        labels = feature[\"labels\"]\n        new_labels = [-100] * len(labels)\n        for word_id in np.where(mask)[0]:\n            word_id = word_id.item()\n            for idx in mapping[word_id]:\n                new_labels[idx] = labels[idx]\n                input_ids[idx] = tokenizer.mask_token_id\n\n    return default_data_collator(features)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:51:07.551015Z","iopub.execute_input":"2021-12-31T05:51:07.551372Z","iopub.status.idle":"2021-12-31T05:51:07.561640Z","shell.execute_reply.started":"2021-12-31T05:51:07.551331Z","shell.execute_reply":"2021-12-31T05:51:07.560310Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"samples = [lm_datasets[i] for i in range(2)]\nbatch = whole_word_masking_data_collator(samples)\n\nfor chunk in batch[\"input_ids\"]:\n    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:51:07.563024Z","iopub.execute_input":"2021-12-31T05:51:07.563239Z","iopub.status.idle":"2021-12-31T05:51:07.579950Z","shell.execute_reply.started":"2021-12-31T05:51:07.563210Z","shell.execute_reply":"2021-12-31T05:51:07.578792Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"train_size = 56186\ntest_size = int(0.1 * train_size)\n\ndataset = lm_datasets.train_test_split(\n    train_size=train_size, test_size=test_size, seed=42\n)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:56:12.517789Z","iopub.execute_input":"2021-12-31T05:56:12.518430Z","iopub.status.idle":"2021-12-31T05:56:12.545492Z","shell.execute_reply.started":"2021-12-31T05:56:12.518397Z","shell.execute_reply":"2021-12-31T05:56:12.544323Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nbatch_size = 64\n# Show the training loss with every epoch\nlogging_steps = len(dataset[\"train\"]) // batch_size\nmodel_name = model_checkpoint.split(\"/\")[-1]\n\ntraining_args = TrainingArguments(\n    output_dir=f\"{model_name}-finetuned-evaluating-student-writing\",\n    overwrite_output_dir=True,\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    push_to_hub=True,\n    fp16=True,\n    logging_steps=logging_steps,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:56:45.876690Z","iopub.execute_input":"2021-12-31T05:56:45.877008Z","iopub.status.idle":"2021-12-31T05:56:45.959994Z","shell.execute_reply.started":"2021-12-31T05:56:45.876977Z","shell.execute_reply":"2021-12-31T05:56:45.959070Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    data_collator=data_collator,\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:57:04.880478Z","iopub.execute_input":"2021-12-31T05:57:04.880807Z","iopub.status.idle":"2021-12-31T05:57:18.193012Z","shell.execute_reply.started":"2021-12-31T05:57:04.880750Z","shell.execute_reply":"2021-12-31T05:57:18.191965Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"import math\n\n# eval_results = trainer.evaluate()\n# print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:57:18.196476Z","iopub.execute_input":"2021-12-31T05:57:18.196907Z","iopub.status.idle":"2021-12-31T05:57:18.201833Z","shell.execute_reply.started":"2021-12-31T05:57:18.196854Z","shell.execute_reply":"2021-12-31T05:57:18.200691Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T05:57:18.203686Z","iopub.execute_input":"2021-12-31T05:57:18.204448Z","iopub.status.idle":"2021-12-31T06:26:50.624214Z","shell.execute_reply.started":"2021-12-31T05:57:18.204403Z","shell.execute_reply":"2021-12-31T06:26:50.622929Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"eval_results = trainer.evaluate()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-31T06:26:50.627296Z","iopub.execute_input":"2021-12-31T06:26:50.628225Z","iopub.status.idle":"2021-12-31T06:27:08.281217Z","shell.execute_reply.started":"2021-12-31T06:26:50.628172Z","shell.execute_reply":"2021-12-31T06:27:08.280260Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")\n# Perplexity for 17% of data is 10.39 and all data 7.33","metadata":{"execution":{"iopub.status.busy":"2021-12-31T06:27:08.286338Z","iopub.execute_input":"2021-12-31T06:27:08.287097Z","iopub.status.idle":"2021-12-31T06:27:08.300279Z","shell.execute_reply.started":"2021-12-31T06:27:08.287051Z","shell.execute_reply":"2021-12-31T06:27:08.299074Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2021-12-31T06:27:08.305307Z","iopub.execute_input":"2021-12-31T06:27:08.306217Z","iopub.status.idle":"2021-12-31T06:28:09.836403Z","shell.execute_reply.started":"2021-12-31T06:27:08.306171Z","shell.execute_reply":"2021-12-31T06:28:09.835349Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM\n\nmodel_checkpoint = \"NahedAbdelgaber/distilbert-base-uncased-finetuned-evaluating-student-writing\"\nfined_tunned_model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2021-12-31T06:36:08.385066Z","iopub.execute_input":"2021-12-31T06:36:08.385335Z","iopub.status.idle":"2021-12-31T06:36:10.415868Z","shell.execute_reply.started":"2021-12-31T06:36:08.385306Z","shell.execute_reply":"2021-12-31T06:36:10.414990Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"import torch\n\ninputs = tokenizer(text, return_tensors=\"pt\")\ntoken_logits = fined_tunned_model(**inputs).logits\n# Find the location of [MASK] and extract its logits\nmask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\nmask_token_logits = token_logits[0, mask_token_index, :]\n# Pick the [MASK] candidates with the highest logits\ntop_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n\nfor token in top_5_tokens:\n    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")","metadata":{"execution":{"iopub.status.busy":"2021-12-31T06:36:50.037734Z","iopub.execute_input":"2021-12-31T06:36:50.038031Z","iopub.status.idle":"2021-12-31T06:36:50.131047Z","shell.execute_reply.started":"2021-12-31T06:36:50.038001Z","shell.execute_reply":"2021-12-31T06:36:50.129821Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}